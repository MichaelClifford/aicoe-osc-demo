{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "395f44cf",
   "metadata": {},
   "source": [
    "# Demo 3 - Data Ingestion\n",
    "\n",
    "This notebook reads the inference from ceph s3 storage for demo2 and will ingest these inference as a table to trino. These tables will be used for creating visualizations using Apache Superset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd4bb47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pathlib\n",
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "import trino\n",
    "import pandas as pd\n",
    "import glob\n",
    "import config\n",
    "from src.data.s3_communication import S3Communication, S3FileType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2fe317",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Injecting Credentials\n",
    "\n",
    "In order to run this notebook, we need credentials to connect with S3 storage to retrieve data and the Trino server to create tables.\n",
    "\n",
    "In an automated environment, the credentials can be specified in a pipeline's environment variables or through Openshift secrets.\n",
    "\n",
    "For running the notebook in a local environment, we will define them as environment variables in a `credentials.env` file at the root of the project repository, and load them using dotenv. An example of what the contents of `credentials.env` could look like is shown below\n",
    "\n",
    "```\n",
    "# s3 credentials\n",
    "S3_ENDPOINT=https://s3.us-east-1.amazonaws.com\n",
    "S3_BUCKET=ocp-odh-os-demo-s3\n",
    "S3_ACCESS_KEY=xxx\n",
    "S3_SECRET_KEY=xxx\n",
    "\n",
    "# trino credentials\n",
    "TRINO_USER=xxx\n",
    "TRINO_PASSWD=xxx\n",
    "TRINO_HOST=trino-secure-odh-trino.apps.odh-cl1.apps.os-climate.org\n",
    "TRINO_PORT=443\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a84efa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "dotenv_dir = \"/opt/app-root/src/aicoe-osc-demo\"\n",
    "dotenv_path = pathlib.Path(dotenv_dir) / \"credentials.env\"\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path, override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78368e2",
   "metadata": {},
   "source": [
    "## Read Raw Data from S3\n",
    "\n",
    "First, we will read some sample data from s3. We will format the column data types to ensure they can be understood by Trino, as well as rename the columns so that they are compatible with SQL naming conventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "466e8eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init s3 connector\n",
    "s3c = S3Communication(\n",
    "    s3_endpoint_url=os.getenv(\"S3_ENDPOINT\"),\n",
    "    aws_access_key_id=os.getenv(\"S3_ACCESS_KEY\"),\n",
    "    aws_secret_access_key=os.getenv(\"S3_SECRET_KEY\"),\n",
    "    s3_bucket=os.getenv(\"S3_BUCKET\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269aa2fb-e410-49b5-a80e-42fba3874604",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"AUTOMATION\"):\n",
    "    if not os.path.exists(config.BASE_INFER_KPI_FOLDER):\n",
    "        pathlib.Path(config.BASE_INFER_KPI_FOLDER).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4f4bdf6-8b20-42a4-9a74-552bfbcec2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>kpi</th>\n",
       "      <th>kpi_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>page</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "      <th>no_ans_score</th>\n",
       "      <th>no_answer_score_plus_boost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88094292_Carriage Svcs Inc_2019-07-23</td>\n",
       "      <td>In which year was the annual report or the sus...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>February 15, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>CARRIAGE SERVICES, INC. (the Company) CORPORAT...</td>\n",
       "      <td>Text</td>\n",
       "      <td>8.340651</td>\n",
       "      <td>-9.459158</td>\n",
       "      <td>-24.459158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88094292_Carriage Svcs Inc_2019-07-23</td>\n",
       "      <td>What is the company name?</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>STOCKHOLDER</td>\n",
       "      <td>5</td>\n",
       "      <td>STOCKHOLDER COMMUNICATIONS WITH DIRECTORS</td>\n",
       "      <td>Text</td>\n",
       "      <td>11.089085</td>\n",
       "      <td>-5.213636</td>\n",
       "      <td>-20.213636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90044053_Fisher &amp; Paykel Hl_2017-11-07</td>\n",
       "      <td>In which year was the annual report or the sus...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Corporate Responsibility and Sustainability Re...</td>\n",
       "      <td>Text</td>\n",
       "      <td>11.549622</td>\n",
       "      <td>-8.787028</td>\n",
       "      <td>-23.787028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90044053_Fisher &amp; Paykel Hl_2017-11-07</td>\n",
       "      <td>In which year was the annual report or the sus...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>Corporate Responsibility and Sustainability Re...</td>\n",
       "      <td>Text</td>\n",
       "      <td>11.549622</td>\n",
       "      <td>-8.787028</td>\n",
       "      <td>-23.787028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90044053_Fisher &amp; Paykel Hl_2017-11-07</td>\n",
       "      <td>In which year was the annual report or the sus...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>Corporate Responsibility and Sustainability Re...</td>\n",
       "      <td>Text</td>\n",
       "      <td>11.549622</td>\n",
       "      <td>-8.787028</td>\n",
       "      <td>-23.787028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 pdf_name  \\\n",
       "0   88094292_Carriage Svcs Inc_2019-07-23   \n",
       "1   88094292_Carriage Svcs Inc_2019-07-23   \n",
       "2  90044053_Fisher & Paykel Hl_2017-11-07   \n",
       "3  90044053_Fisher & Paykel Hl_2017-11-07   \n",
       "4  90044053_Fisher & Paykel Hl_2017-11-07   \n",
       "\n",
       "                                                 kpi  kpi_id  \\\n",
       "0  In which year was the annual report or the sus...    <NA>   \n",
       "1                          What is the company name?    <NA>   \n",
       "2  In which year was the annual report or the sus...    <NA>   \n",
       "3  In which year was the annual report or the sus...    <NA>   \n",
       "4  In which year was the annual report or the sus...    <NA>   \n",
       "\n",
       "              answer  page                                          paragraph  \\\n",
       "0  February 15, 2017     0  CARRIAGE SERVICES, INC. (the Company) CORPORAT...   \n",
       "1        STOCKHOLDER     5         STOCKHOLDER COMMUNICATIONS WITH DIRECTORS    \n",
       "2               2017     1  Corporate Responsibility and Sustainability Re...   \n",
       "3               2017     2  Corporate Responsibility and Sustainability Re...   \n",
       "4               2017     3  Corporate Responsibility and Sustainability Re...   \n",
       "\n",
       "  source      score  no_ans_score  no_answer_score_plus_boost  \n",
       "0   Text   8.340651     -9.459158                  -24.459158  \n",
       "1   Text  11.089085     -5.213636                  -20.213636  \n",
       "2   Text  11.549622     -8.787028                  -23.787028  \n",
       "3   Text  11.549622     -8.787028                  -23.787028  \n",
       "4   Text  11.549622     -8.787028                  -23.787028  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download a sample dataset file from s3\n",
    "s3c.download_files_in_prefix_to_dir(\n",
    "  s3_prefix=config.BASE_INFER_KPI_S3_PREFIX,\n",
    "  destination_dir=config.BASE_INFER_KPI_FOLDER\n",
    ")\n",
    "\n",
    "all_files = glob.glob(str(config.BASE_INFER_KPI_FOLDER / \"*.csv\"))\n",
    "list_of_files =  []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0).convert_dtypes().drop(columns=['Unnamed: 0'],axis=1)\n",
    "    list_of_files.append(df)\n",
    "\n",
    "preds_kpi = pd.concat(list_of_files, axis=0, ignore_index=True)\n",
    "\n",
    "len_preds_kpi = len(preds_kpi)\n",
    "\n",
    "# convert columns to specific data types\n",
    "preds_kpi = preds_kpi.convert_dtypes().drop(['index'], axis =1)\n",
    "preds_kpi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f87ac21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Erik Erlandson <eje@redhat.com>\n",
    "\n",
    "_p2smap = {\"string\": \"varchar\", \"Float64\": \"double\", \"Int64\": \"bigint\"}\n",
    "\n",
    "def pandas_type_to_sql(pt):\n",
    "    st = _p2smap.get(pt)\n",
    "    if st is not None:\n",
    "        return st\n",
    "    raise ValueError(\"unexpected pandas column type '{pt}'\".format(pt=pt))\n",
    "\n",
    "\n",
    "# add ability to specify optional dict for specific fields?\n",
    "# if column name is present, use specified value?\n",
    "def generate_table_schema_pairs(df):\n",
    "    ptypes = [str(e) for e in df.dtypes.to_list()]\n",
    "    stypes = [pandas_type_to_sql(e) for e in ptypes]\n",
    "    pz = list(zip(df.columns.to_list(), stypes))\n",
    "    return \",\\n\".join([\"    {n} {t}\".format(n=e[0], t=e[1]) for e in pz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5230c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 189 entries, 0 to 188\n",
      "Data columns (total 10 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   pdf_name                    189 non-null    string \n",
      " 1   kpi                         189 non-null    string \n",
      " 2   kpi_id                      0 non-null      Int64  \n",
      " 3   answer                      189 non-null    string \n",
      " 4   page                        153 non-null    Int64  \n",
      " 5   paragraph                   153 non-null    string \n",
      " 6   source                      189 non-null    string \n",
      " 7   score                       189 non-null    Float64\n",
      " 8   no_ans_score                153 non-null    Float64\n",
      " 9   no_answer_score_plus_boost  153 non-null    Float64\n",
      "dtypes: Float64(3), Int64(2), string(5)\n",
      "memory usage: 15.8 KB\n"
     ]
    }
   ],
   "source": [
    "# a way to examine the structure of a pandas data frame\n",
    "preds_kpi.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4078824e",
   "metadata": {},
   "source": [
    "## Save Processed Data to S3\n",
    "\n",
    "Now that our data is in a form ingestible by Trino, we will upload it back into our s3 bucket. This will be the data source for our Trino table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72b3795f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '7E0YWRPW9BZXJJES',\n",
       "  'HostId': 'pmOx4DZ87XfX4q6qMVcth/odZWbjv5KpYFxi+XrxdWZ3jRnFIBowk0jLAXjCKtcmVUfvH9FTe8g=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'pmOx4DZ87XfX4q6qMVcth/odZWbjv5KpYFxi+XrxdWZ3jRnFIBowk0jLAXjCKtcmVUfvH9FTe8g=',\n",
       "   'x-amz-request-id': '7E0YWRPW9BZXJJES',\n",
       "   'date': 'Thu, 18 Nov 2021 21:46:20 GMT',\n",
       "   'etag': '\"4a89f6b6e30e83f156e1480daf2c4f9d\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"4a89f6b6e30e83f156e1480daf2c4f9d\"'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parquet has multiple options for appending or updating data\n",
    "# including adding new files, or appending, sharding directory trees, etc\n",
    "s3c.upload_df_to_s3(\n",
    "    preds_kpi,\n",
    "    s3_prefix=config.BASE_INFER_KPI_TABLE_S3_PREFIX,\n",
    "    s3_key=\"kpi_processed.parquet\",\n",
    "    filetype=S3FileType.PARQUET,\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b8af31",
   "metadata": {},
   "source": [
    "## Create a Table on Trino\n",
    "\n",
    "Finally, we will create a table in our Trino database that uses the parquet files we uploaded in the previous section as the data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "950868a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use trino password env-var to hold token values\n",
    "JWT_TOKEN = os.environ['TRINO_PASSWD']\n",
    "conn = trino.dbapi.connect(\n",
    "    host=os.environ['TRINO_HOST'],\n",
    "    port=os.environ['TRINO_PORT'],\n",
    "    user=os.environ['TRINO_USER'],\n",
    "    http_scheme='https',\n",
    "    auth=trino.auth.JWTAuthentication(JWT_TOKEN),\n",
    ")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d4860b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[True]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a sql schema that will correspond to the data types\n",
    "# of columns in the pandas DF\n",
    "# to-do: add some mechanisms for overriding types, either here\n",
    "# or on the pandas data-frame itself before we write it out\n",
    "schema = generate_table_schema_pairs(preds_kpi)\n",
    "\n",
    "tabledef = \"\"\"create table if not exists osc_datacommons_dev.urgentem.infer_kpi(\n",
    "{schema}\n",
    ") with (\n",
    "    format = 'parquet',\n",
    "    external_location = 's3a://{s3_bucket}/corpdata/ESG/KPI_table/'\n",
    ")\"\"\".format(\n",
    "    schema=schema,\n",
    "    s3_bucket=os.environ[\"S3_BUCKET\"],\n",
    ")\n",
    "# tables created externally may not show up immediately in cloud-beaver\n",
    "cur.execute(tabledef)\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee568250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['75506106_BOA_2016-12-31',\n",
       " 'In which year was the annual report or the sustainability report published?',\n",
       " None,\n",
       " '2016',\n",
       " 30,\n",
       " ' L’Atelier Finance Climat pour l’Afrique Francophone, 3-5 mai 2016, Casablanca',\n",
       " 'Text',\n",
       " 11.143327713012695,\n",
       " -9.074384689331056,\n",
       " -24.07438468933105]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check if infer_kpi table is there\n",
    "cur.execute(\"select * from osc_datacommons_dev.urgentem.infer_kpi LIMIT 5\")\n",
    "cur.fetchall()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d0d0a0",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we read inference for KPI sustainability report, 2019 which follows the same format as the output of the KPI Inference model in Demo 2. After reading the report, we automatically infer the data schema from the report, preprocess it and create a table in trino that could be used for visualization in Apache Superset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
